{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次迭代后的结果为: [19. 45. 57.]\n",
      "第2次迭代后的结果为: [18.28652664 29.07291936  0.62690008]\n",
      "第3次迭代后的结果为: [ -3.89371938 -54.6216661   17.45526368]\n",
      "第4次迭代后的结果为: [ 6.1165179  12.53615448  8.0536277 ]\n",
      "第5次迭代后的结果为: [14.26277202 11.67931793  7.98933007]\n",
      "第6次迭代后的结果为: [ 9.99987357 11.99952717  7.99914594]\n",
      "第7次迭代后的结果为: [10.00000116 12.00000658  8.00001866]\n",
      "第8次迭代后的结果为: [10.         12.00000001  8.        ]\n",
      "[10.         12.00000001  8.        ]\n",
      "第1次迭代后的结果为: [19. 45. 57.]\n",
      "第2次迭代后的结果为: [16.72766685 26.79929838  1.64537383]\n",
      "第3次迭代后的结果为: [  4.47621635 -29.07866996  14.81005912]\n",
      "第4次迭代后的结果为: [ 6.54870749 12.37894803  8.00126005]\n",
      "第5次迭代后的结果为: [13.46688907 11.90282066  7.96796237]\n",
      "第6次迭代后的结果为: [ 9.99996528 11.99974993  7.99998457]\n",
      "第7次迭代后的结果为: [10.00000004 12.00000051  8.00000026]\n",
      "[10.00000004 12.00000051  8.00000026]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Use NFGS to solve optimization problem\n",
    "        In this part, you can see two def: bfgs_newton and dfp_newton.\n",
    "    Before you run the code, you need to know which function and how\n",
    "    many unknowns paras you need to solve, then prepare the initial \n",
    "    values(x)、Primitive Function(f) and Jocobian Matrix(jacobian).\n",
    "    And you can see a example in the last section.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sympy import symbols\n",
    "\n",
    "\n",
    "def bfgs_newton(f, x, n, iters):\n",
    "    \"\"\"\n",
    "    BFGS method\n",
    "        :param f: the Primitive Function needed to solve\n",
    "        :param x: the Initial values(n dims)\n",
    "        :param n: the Number of unknowns\n",
    "        :param iters: Maximum number of Iterations\n",
    "        :return: x value\n",
    "    \"\"\"\n",
    "    # 步长。设为1才能收敛，小于1不能收敛\n",
    "    learning_rate = 1\n",
    "    # 初始化B正定矩阵\n",
    "    B = np.eye(n)\n",
    "    x_len = x.shape[0]\n",
    "    # 一阶导g的第二范式的最小值（阈值）\n",
    "    epsilon = 1e-5\n",
    "    for i in range(1, iters):\n",
    "        g = jacobian(f, x)\n",
    "        if np.linalg.norm(g) < epsilon:\n",
    "            break\n",
    "        p = np.linalg.solve(B, g)\n",
    "        # 更新x值\n",
    "        x_new = x - p*learning_rate\n",
    "        print(\"第\" + str(i) + \"次迭代后的结果为:\", x_new)\n",
    "        g_new = jacobian(f, x_new)\n",
    "        y = g_new - g\n",
    "        k = x_new - x\n",
    "        y_t = y.reshape([x_len, 1])\n",
    "        Bk = np.dot(B, k)\n",
    "        k_t_B = np.dot(k, B)\n",
    "        kBk = np.dot(np.dot(k, B), k)\n",
    "        # 更新B正定矩阵。完全按照公式来计算\n",
    "        B = B + y_t*y/np.dot(y, k) - Bk.reshape([x_len, 1]) * k_t_B / kBk\n",
    "        x = x_new\n",
    "    return x\n",
    "\n",
    "\n",
    "def dfp_newton(f, x, n, iters):\n",
    "    \"\"\"\n",
    "    DFP method\n",
    "        :param f: the Primitive Function needed to solve\n",
    "        :param x: the Initial values(n dims)\n",
    "        :param n: the Number of unknowns\n",
    "        :param iters: Maximum number of Iterations\n",
    "        :return: x value\n",
    "    \"\"\"\n",
    "    # 步长\n",
    "    learning_rate = 1\n",
    "    # 初始化B正定矩阵\n",
    "    G = np.eye(n)\n",
    "    x_len = x.shape[0]\n",
    "    # 一阶导g的第二范式的最小值（阈值）\n",
    "    epsilon = 1e-5\n",
    "    for i in range(1, iters):\n",
    "        g = jacobian(f, x)\n",
    "        if np.linalg.norm(g) < epsilon:\n",
    "            break\n",
    "        p = np.dot(G, g)\n",
    "        # 更新x值\n",
    "        x_new = x - p * learning_rate\n",
    "        print(\"第\" + str(i) + \"次迭代后的结果为:\", x_new)\n",
    "        g_new = jacobian(f, x_new)\n",
    "        y = g_new - g\n",
    "        k = x_new - x\n",
    "        Gy = np.dot(G, y)\n",
    "        y_t_G = np.dot(y, G)\n",
    "        yGy = np.dot(np.dot(y, G), y)\n",
    "        # 更新G正定矩阵\n",
    "        G = G + k.reshape([x_len, 1]) * k / np.dot(k, y) - Gy.reshape([x_len, 1]) * y_t_G / yGy\n",
    "        x = x_new\n",
    "    return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## \n",
    "    def jacobian(f, x):\n",
    "        \"\"\"\n",
    "        Define A jocobian matrix\n",
    "            Calculate the First Order Derivative of the Primitive Function\n",
    "        :param f: the Primitive Function needed to solve\n",
    "        :param x: Input values when Iterating\n",
    "        :return: the vector of gradient\n",
    "        \"\"\"\n",
    "        dfdx1 = 2*(x[0]-10)\n",
    "        dfdx2 = 4*(x[1]-12)\n",
    "        dfdx3 = 8*(x[2]-8)\n",
    "        gradient = np.array([dfdx1, dfdx2, dfdx3], dtype=float)\n",
    "        return gradient\n",
    "\n",
    "    # First, define the elements of a three-dimensional vector\n",
    "    x1 = symbols(\"x1\")\n",
    "    x2 = symbols(\"x2\")\n",
    "    x3 = symbols(\"x3\")\n",
    "    x = np.array([1, 1, 1], dtype=float)\n",
    "    f = (x1-10)**2+2*(x2-12)**2+4*(x3-8)**2\n",
    "    print(bfgs_newton(f, x, 3, 2000))\n",
    "    # print(dfp_newton(f, x, 3, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d0a9ebc67e6f017f33b2b49d8e23e3a3188e858a41e82fef0b9959045b729e3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
